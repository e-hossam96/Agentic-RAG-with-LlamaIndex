{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agentic RAG with LlamaIndex\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will walk through the basic concepts to create an agents that orchestrate between two query engine tools as follows.\n",
    "\n",
    "- Define a reader to read the `pdf` sample file [AraGPT2](./data/aragpt2.pdf) paper.\n",
    "- Define a `splitter` to process the texts of the document.\n",
    "- Set the LLM embedding and generation model ids.\n",
    "- Create the engines from the Indexes and define a tool wrapper around them.\n",
    "- Define a router engine to select the proper tool based on the input query.\n",
    "- Use the agent to answer some queries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from rich import print\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load env variables\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some constants\n",
    "GENERATION_MODEL_ID = \"gpt-4o-mini\"\n",
    "EMBEDDING_MODEL_ID = \"text-embedding-3-small\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "documents_reader = SimpleDirectoryReader(input_files=[\"./data/aragpt2.pdf\"])\n",
    "documents = documents_reader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id_</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'b8e65461-168c-4603-a276-a146a13b5fe9'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">embedding</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'page_label'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'1'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'file_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'aragpt2.pdf'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'file_path'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'data/aragpt2.pdf'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'file_type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'application/pdf'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'file_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">457776</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'creation_date'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2024-11-12'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'last_modified_date'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2024-10-22'</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">excluded_embed_metadata_keys</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'file_name'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'file_type'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'file_size'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'creation_date'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'last_modified_date'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'last_accessed_date'</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">excluded_llm_metadata_keys</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'file_name'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'file_type'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'file_size'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'creation_date'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'last_modified_date'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'last_accessed_date'</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">relationships</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">text</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Proceedings of the Sixth Arabic Natural Language Processing Workshop , pages 196–207\\nKyiv, Ukraine </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">(Virtual), April 19, 2021.196ARAGPT2: Pre-T rained Transformer\\nfor Arabic Language Generation\\nWissam Antoun and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Fady Baly and Hazem Hajj\\nAmerican University of Beirut\\n{wfa07, fbg06, hh63 }@aub.edu.lb\\nAbstract\\nRecently, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">pre-trained transformer-based archi-\\ntectures have proven to be very efﬁcient atlanguage modeling and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">understanding, giventhat they are trained on a large enough cor-pus. Applications in language generation </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">for\\nArabic are still lagging in comparison to other\\nNLP advances primarily due to the lack ofadvanced Arabic </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">language generation models.In this paper, we develop the ﬁrst advanced\\nArabic language generation model, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">AraGPT2,\\ntrained from scratch on a large Arabic corpusof internet text and news articles. Our largest\\nmodel, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">A\\nRAGPT2- MEGA , has 1.46 billion pa-\\nrameters, which makes it the largest Arabiclanguage model available. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">The\\nMEGA model\\nwas evaluated and showed success on different\\ntasks including synthetic news generation, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">andzero-shot question answering. For text gener-\\nation, our best model achieves a perplexity of\\n29.8 on held-out </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Wikipedia articles. A studyconducted with human evaluators showed thesigniﬁcant success of AraGPT2-mega in </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">gen-erating news articles that are difﬁcult to dis-tinguish from articles written by humans. Wethus develop and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">release an automatic discrim-inator model with a 98% percent accuracy indetecting model-generated text. The </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">modelsare also publicly available\\n1, hoping to encour-\\nage new research directions and applicationsfor Arabic </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">NLP.\\n1 Introduction\\nFew years ago, Natural language processing\\n(NLP) was revolutionized with the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">introduction\\nof multi-head self-attention transformer architec-ture ( Vaswani et al. ,2017 ). The </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">transformer\\nachieved superior performance compared to recur-\\nrent neural networks several NLP tasks </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">including\\nmachine translation, sentence classiﬁcation with\\n1Pretrained variants of A RAGPT2 (base, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">medium,\\nlarge, mega) and discriminator are publicly available </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">on\\ngithub.com/aub-mind/arabert/tree/master/aragpt2BERT ( Devlin et al. ,2019 ), and ELECTRA ( Clark\\net al. ,2020b</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">), and sentence completion with GPT-\\n2(Radford et al. ,2019 ), GROVER ( Zellers et al. ,\\n2019 ), and CTRL ( </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Keskar et al. ,2019 ). Recent\\nworks have shown that larger models pre-trained\\non larger datasets can further </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">improve performancei.e. RoBERTa ( Liu et al. ,2019 ), and XLM-R ( Con-\\nneau et al. ,2019 ).\\nOn the other hand, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">work on Arabic language\\nmodeling has mostly targeted natural language\\nunderstanding (NLU) by pre-training </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">transformer-\\nbased models using the Masked Language Model-\\ning (MLM) task i.e. A RABERT ( Antoun et al. ,\\n2020a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">). In contrast, Arabic text generation or\\ncausal language modeling hasn’t received much\\nattention. Few works such</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">as hULMonA ( ElJundi\\net al. ,2019 ) used next word prediction as a pre-\\ntraining task in for transfer learning in</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Arabic text\\nclassiﬁcation. ( Khooli ,2020 ) and ( Doiron ,2020 )\\nleveraged the existing GPT2 English model </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">andadapted it for Arabic using text from the Arabic\\nWikipedia dumps, which is sub-optimal for Arabic.\\nIn this </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">paper, the ﬁrst advanced language gener-\\nation models built from the grounds up on Arabic\\nlanguage have been </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">developed. The process of pre-\\ntraining A RAGPT2, a GPT -2 transformer model\\nfor the Arabic language is </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">described. The modelcomes in 4 size variants:\\nbase (135M2),medium\\n(370M), large (792M) and mega (1.46B3), </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">which\\nallows the exploration of A RAGPT2 in multiple ap-\\nplications with different data availability and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">com-\\nputational constraints. The perplexity measure is\\nused to automatically evaluate A RAGPT2. Fur-\\nthermore, a</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">human-based evaluation is provided,\\nwhich highlights the ability of A RAGPT2 to de-\\nceive human evaluators. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Finally, an A RAELEC-\\nTRA ( Antoun et al. ,2020b ) based detector is devel-\\n2Million Parameters\\n3Billion </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Parameters'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">mimetype</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'text/plain'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">start_char_idx</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">end_char_idx</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">text_template</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'{metadata_str}\\n\\n{content}'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">metadata_template</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'{key}: {value}'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">metadata_seperator</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'\\n'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid_\u001b[0m=\u001b[32m'b8e65461-168c-4603-a276-a146a13b5fe9'\u001b[0m,\n",
       "    \u001b[33membedding\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "        \u001b[32m'page_label'\u001b[0m: \u001b[32m'1'\u001b[0m,\n",
       "        \u001b[32m'file_name'\u001b[0m: \u001b[32m'aragpt2.pdf'\u001b[0m,\n",
       "        \u001b[32m'file_path'\u001b[0m: \u001b[32m'data/aragpt2.pdf'\u001b[0m,\n",
       "        \u001b[32m'file_type'\u001b[0m: \u001b[32m'application/pdf'\u001b[0m,\n",
       "        \u001b[32m'file_size'\u001b[0m: \u001b[1;36m457776\u001b[0m,\n",
       "        \u001b[32m'creation_date'\u001b[0m: \u001b[32m'2024-11-12'\u001b[0m,\n",
       "        \u001b[32m'last_modified_date'\u001b[0m: \u001b[32m'2024-10-22'\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[33mexcluded_embed_metadata_keys\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[32m'file_name'\u001b[0m,\n",
       "        \u001b[32m'file_type'\u001b[0m,\n",
       "        \u001b[32m'file_size'\u001b[0m,\n",
       "        \u001b[32m'creation_date'\u001b[0m,\n",
       "        \u001b[32m'last_modified_date'\u001b[0m,\n",
       "        \u001b[32m'last_accessed_date'\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mexcluded_llm_metadata_keys\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[32m'file_name'\u001b[0m,\n",
       "        \u001b[32m'file_type'\u001b[0m,\n",
       "        \u001b[32m'file_size'\u001b[0m,\n",
       "        \u001b[32m'creation_date'\u001b[0m,\n",
       "        \u001b[32m'last_modified_date'\u001b[0m,\n",
       "        \u001b[32m'last_accessed_date'\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mrelationships\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[33mtext\u001b[0m=\u001b[32m'Proceedings of the Sixth Arabic Natural Language Processing Workshop , pages 196–207\\nKyiv, Ukraine \u001b[0m\n",
       "\u001b[32m(\u001b[0m\u001b[32mVirtual\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, April 19, 2021.196ARAGPT2: Pre-T rained Transformer\\nfor Arabic Language Generation\\nWissam Antoun and \u001b[0m\n",
       "\u001b[32mFady Baly and Hazem Hajj\\nAmerican University of Beirut\\n\u001b[0m\u001b[32m{\u001b[0m\u001b[32mwfa07, fbg06, hh63 \u001b[0m\u001b[32m}\u001b[0m\u001b[32m@aub.edu.lb\\nAbstract\\nRecently, \u001b[0m\n",
       "\u001b[32mpre-trained transformer-based archi-\\ntectures have proven to be very efﬁcient atlanguage modeling and \u001b[0m\n",
       "\u001b[32munderstanding, giventhat they are trained on a large enough cor-pus. Applications in language generation \u001b[0m\n",
       "\u001b[32mfor\\nArabic are still lagging in comparison to other\\nNLP advances primarily due to the lack ofadvanced Arabic \u001b[0m\n",
       "\u001b[32mlanguage generation models.In this paper, we develop the ﬁrst advanced\\nArabic language generation model, \u001b[0m\n",
       "\u001b[32mAraGPT2,\\ntrained from scratch on a large Arabic corpusof internet text and news articles. Our largest\\nmodel, \u001b[0m\n",
       "\u001b[32mA\\nRAGPT2- MEGA , has 1.46 billion pa-\\nrameters, which makes it the largest Arabiclanguage model available. \u001b[0m\n",
       "\u001b[32mThe\\nMEGA model\\nwas evaluated and showed success on different\\ntasks including synthetic news generation, \u001b[0m\n",
       "\u001b[32mandzero-shot question answering. For text gener-\\nation, our best model achieves a perplexity of\\n29.8 on held-out \u001b[0m\n",
       "\u001b[32mWikipedia articles. A studyconducted with human evaluators showed thesigniﬁcant success of AraGPT2-mega in \u001b[0m\n",
       "\u001b[32mgen-erating news articles that are difﬁcult to dis-tinguish from articles written by humans. Wethus develop and \u001b[0m\n",
       "\u001b[32mrelease an automatic discrim-inator model with a 98% percent accuracy indetecting model-generated text. The \u001b[0m\n",
       "\u001b[32mmodelsare also publicly available\\n1, hoping to encour-\\nage new research directions and applicationsfor Arabic \u001b[0m\n",
       "\u001b[32mNLP.\\n1 Introduction\\nFew years ago, Natural language processing\\n\u001b[0m\u001b[32m(\u001b[0m\u001b[32mNLP\u001b[0m\u001b[32m)\u001b[0m\u001b[32m was revolutionized with the \u001b[0m\n",
       "\u001b[32mintroduction\\nof multi-head self-attention transformer architec-ture \u001b[0m\u001b[32m(\u001b[0m\u001b[32m Vaswani et al. ,2017 \u001b[0m\u001b[32m)\u001b[0m\u001b[32m. The \u001b[0m\n",
       "\u001b[32mtransformer\\nachieved superior performance compared to recur-\\nrent neural networks several NLP tasks \u001b[0m\n",
       "\u001b[32mincluding\\nmachine translation, sentence classiﬁcation with\\n1Pretrained variants of A RAGPT2 \u001b[0m\u001b[32m(\u001b[0m\u001b[32mbase, \u001b[0m\n",
       "\u001b[32mmedium,\\nlarge, mega\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and discriminator are publicly available \u001b[0m\n",
       "\u001b[32mon\\ngithub.com/aub-mind/arabert/tree/master/aragpt2BERT \u001b[0m\u001b[32m(\u001b[0m\u001b[32m Devlin et al. ,2019 \u001b[0m\u001b[32m)\u001b[0m\u001b[32m, and ELECTRA \u001b[0m\u001b[32m(\u001b[0m\u001b[32m Clark\\net al. ,2020b\u001b[0m\n",
       "\u001b[32m)\u001b[0m\u001b[32m, and sentence completion with GPT-\\n2\u001b[0m\u001b[32m(\u001b[0m\u001b[32mRadford et al. ,2019 \u001b[0m\u001b[32m)\u001b[0m\u001b[32m, GROVER \u001b[0m\u001b[32m(\u001b[0m\u001b[32m Zellers et al. ,\\n2019 \u001b[0m\u001b[32m)\u001b[0m\u001b[32m, and CTRL \u001b[0m\u001b[32m(\u001b[0m\u001b[32m \u001b[0m\n",
       "\u001b[32mKeskar et al. ,2019 \u001b[0m\u001b[32m)\u001b[0m\u001b[32m. Recent\\nworks have shown that larger models pre-trained\\non larger datasets can further \u001b[0m\n",
       "\u001b[32mimprove performancei.e. RoBERTa \u001b[0m\u001b[32m(\u001b[0m\u001b[32m Liu et al. ,2019 \u001b[0m\u001b[32m)\u001b[0m\u001b[32m, and XLM-R \u001b[0m\u001b[32m(\u001b[0m\u001b[32m Con-\\nneau et al. ,2019 \u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\nOn the other hand, \u001b[0m\n",
       "\u001b[32mwork on Arabic language\\nmodeling has mostly targeted natural language\\nunderstanding \u001b[0m\u001b[32m(\u001b[0m\u001b[32mNLU\u001b[0m\u001b[32m)\u001b[0m\u001b[32m by pre-training \u001b[0m\n",
       "\u001b[32mtransformer-\\nbased models using the Masked Language Model-\\ning \u001b[0m\u001b[32m(\u001b[0m\u001b[32mMLM\u001b[0m\u001b[32m)\u001b[0m\u001b[32m task i.e. A RABERT \u001b[0m\u001b[32m(\u001b[0m\u001b[32m Antoun et al. ,\\n2020a \u001b[0m\n",
       "\u001b[32m)\u001b[0m\u001b[32m. In contrast, Arabic text generation or\\ncausal language modeling hasn’t received much\\nattention. Few works such\u001b[0m\n",
       "\u001b[32mas hULMonA \u001b[0m\u001b[32m(\u001b[0m\u001b[32m ElJundi\\net al. ,2019 \u001b[0m\u001b[32m)\u001b[0m\u001b[32m used next word prediction as a pre-\\ntraining task in for transfer learning in\u001b[0m\n",
       "\u001b[32mArabic text\\nclassiﬁcation. \u001b[0m\u001b[32m(\u001b[0m\u001b[32m Khooli ,2020 \u001b[0m\u001b[32m)\u001b[0m\u001b[32m and \u001b[0m\u001b[32m(\u001b[0m\u001b[32m Doiron ,2020 \u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nleveraged the existing GPT2 English model \u001b[0m\n",
       "\u001b[32mandadapted it for Arabic using text from the Arabic\\nWikipedia dumps, which is sub-optimal for Arabic.\\nIn this \u001b[0m\n",
       "\u001b[32mpaper, the ﬁrst advanced language gener-\\nation models built from the grounds up on Arabic\\nlanguage have been \u001b[0m\n",
       "\u001b[32mdeveloped. The process of pre-\\ntraining A RAGPT2, a GPT -2 transformer model\\nfor the Arabic language is \u001b[0m\n",
       "\u001b[32mdescribed. The modelcomes in 4 size variants:\\nbase \u001b[0m\u001b[32m(\u001b[0m\u001b[32m135M2\u001b[0m\u001b[32m)\u001b[0m\u001b[32m,medium\\n\u001b[0m\u001b[32m(\u001b[0m\u001b[32m370M\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, large \u001b[0m\u001b[32m(\u001b[0m\u001b[32m792M\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and mega \u001b[0m\u001b[32m(\u001b[0m\u001b[32m1.46B3\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, \u001b[0m\n",
       "\u001b[32mwhich\\nallows the exploration of A RAGPT2 in multiple ap-\\nplications with different data availability and \u001b[0m\n",
       "\u001b[32mcom-\\nputational constraints. The perplexity measure is\\nused to automatically evaluate A RAGPT2. Fur-\\nthermore, a\u001b[0m\n",
       "\u001b[32mhuman-based evaluation is provided,\\nwhich highlights the ability of A RAGPT2 to de-\\nceive human evaluators. \u001b[0m\n",
       "\u001b[32mFinally, an A RAELEC-\\nTRA \u001b[0m\u001b[32m(\u001b[0m\u001b[32m Antoun et al. ,2020b \u001b[0m\u001b[32m)\u001b[0m\u001b[32m based detector is devel-\\n2Million Parameters\\n3Billion \u001b[0m\n",
       "\u001b[32mParameters'\u001b[0m,\n",
       "    \u001b[33mmimetype\u001b[0m=\u001b[32m'text/plain'\u001b[0m,\n",
       "    \u001b[33mstart_char_idx\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mend_char_idx\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mtext_template\u001b[0m=\u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32mmetadata_str\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\n\u001b[0m\u001b[32m{\u001b[0m\u001b[32mcontent\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m,\n",
       "    \u001b[33mmetadata_template\u001b[0m=\u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32mkey\u001b[0m\u001b[32m}\u001b[0m\u001b[32m: \u001b[0m\u001b[32m{\u001b[0m\u001b[32mvalue\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m,\n",
       "    \u001b[33mmetadata_seperator\u001b[0m=\u001b[32m'\\n'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "sentence_splitter = SentenceSplitter(chunk_size=512, chunk_overlap=32)\n",
    "nodes = sentence_splitter.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">89</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m89\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TextNode</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id_</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'769ef720-fbb9-41e9-86e7-87151b333204'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">embedding</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'page_label'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'1'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'file_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'aragpt2.pdf'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'file_path'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'data/aragpt2.pdf'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'file_type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'application/pdf'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'file_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">457776</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'creation_date'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2024-11-12'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'last_modified_date'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2024-10-22'</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">excluded_embed_metadata_keys</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'file_name'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'file_type'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'file_size'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'creation_date'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'last_modified_date'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'last_accessed_date'</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">excluded_llm_metadata_keys</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'file_name'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'file_type'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'file_size'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'creation_date'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'last_modified_date'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'last_accessed_date'</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">relationships</span>=<span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">NodeRelationship.SOURCE:</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #008000; text-decoration-color: #008000\">'1'</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;: </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RelatedNodeInfo</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">node_id</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'b8e65461-168c-4603-a276-a146a13b5fe9'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">node_type</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;ObjectType.DOCUMENT: </span><span style=\"color: #008000; text-decoration-color: #008000\">'4'</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">metadata</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #008000; text-decoration-color: #008000\">'page_label'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'1'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #008000; text-decoration-color: #008000\">'file_name'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'aragpt2.pdf'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #008000; text-decoration-color: #008000\">'file_path'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'data/aragpt2.pdf'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #008000; text-decoration-color: #008000\">'file_type'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'application/pdf'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #008000; text-decoration-color: #008000\">'file_size'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">457776</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #008000; text-decoration-color: #008000\">'creation_date'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'2024-11-12'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #008000; text-decoration-color: #008000\">'last_modified_date'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'2024-10-22'</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">}</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">hash</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'be467e8635c423cf5e905a9469550ed6e5194fba229387b29d1ef0cf335d08de'</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">        &lt;NodeRelationship.NEXT: </span><span style=\"color: #008000; text-decoration-color: #008000\">'3'</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;: </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RelatedNodeInfo</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">node_id</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'6991976f-1ca4-4766-900b-1ecce132c2a0'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">node_type</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;ObjectType.TEXT: </span><span style=\"color: #008000; text-decoration-color: #008000\">'1'</span><span style=\"font-weight: bold\">&gt;</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">hash</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'2d3aa208bc0bae83732ad747eb239cc40eef454a4e693b6422ba4afc8288cdd5'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">text</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Proceedings of the Sixth Arabic Natural Language Processing Workshop , pages 196–207\\nKyiv, Ukraine </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">(Virtual), April 19, 2021.196ARAGPT2: Pre-T rained Transformer\\nfor Arabic Language Generation\\nWissam Antoun and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Fady Baly and Hazem Hajj\\nAmerican University of Beirut\\n{wfa07, fbg06, hh63 }@aub.edu.lb\\nAbstract\\nRecently, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">pre-trained transformer-based archi-\\ntectures have proven to be very efﬁcient atlanguage modeling and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">understanding, giventhat they are trained on a large enough cor-pus. Applications in language generation </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">for\\nArabic are still lagging in comparison to other\\nNLP advances primarily due to the lack ofadvanced Arabic </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">language generation models.In this paper, we develop the ﬁrst advanced\\nArabic language generation model, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">AraGPT2,\\ntrained from scratch on a large Arabic corpusof internet text and news articles. Our largest\\nmodel, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">A\\nRAGPT2- MEGA , has 1.46 billion pa-\\nrameters, which makes it the largest Arabiclanguage model available. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">The\\nMEGA model\\nwas evaluated and showed success on different\\ntasks including synthetic news generation, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">andzero-shot question answering. For text gener-\\nation, our best model achieves a perplexity of\\n29.8 on held-out </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Wikipedia articles. A studyconducted with human evaluators showed thesigniﬁcant success of AraGPT2-mega in </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">gen-erating news articles that are difﬁcult to dis-tinguish from articles written by humans. Wethus develop and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">release an automatic discrim-inator model with a 98% percent accuracy indetecting model-generated text. The </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">modelsare also publicly available\\n1, hoping to encour-\\nage new research directions and applicationsfor Arabic </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">NLP.\\n1 Introduction\\nFew years ago, Natural language processing\\n(NLP) was revolutionized with the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">introduction\\nof multi-head self-attention transformer architec-ture ( Vaswani et al. ,2017 ).'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">mimetype</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'text/plain'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">start_char_idx</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">end_char_idx</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1799</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">text_template</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'{metadata_str}\\n\\n{content}'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">metadata_template</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'{key}: {value}'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">metadata_seperator</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'\\n'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mTextNode\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid_\u001b[0m=\u001b[32m'769ef720-fbb9-41e9-86e7-87151b333204'\u001b[0m,\n",
       "    \u001b[33membedding\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "        \u001b[32m'page_label'\u001b[0m: \u001b[32m'1'\u001b[0m,\n",
       "        \u001b[32m'file_name'\u001b[0m: \u001b[32m'aragpt2.pdf'\u001b[0m,\n",
       "        \u001b[32m'file_path'\u001b[0m: \u001b[32m'data/aragpt2.pdf'\u001b[0m,\n",
       "        \u001b[32m'file_type'\u001b[0m: \u001b[32m'application/pdf'\u001b[0m,\n",
       "        \u001b[32m'file_size'\u001b[0m: \u001b[1;36m457776\u001b[0m,\n",
       "        \u001b[32m'creation_date'\u001b[0m: \u001b[32m'2024-11-12'\u001b[0m,\n",
       "        \u001b[32m'last_modified_date'\u001b[0m: \u001b[32m'2024-10-22'\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[33mexcluded_embed_metadata_keys\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[32m'file_name'\u001b[0m,\n",
       "        \u001b[32m'file_type'\u001b[0m,\n",
       "        \u001b[32m'file_size'\u001b[0m,\n",
       "        \u001b[32m'creation_date'\u001b[0m,\n",
       "        \u001b[32m'last_modified_date'\u001b[0m,\n",
       "        \u001b[32m'last_accessed_date'\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mexcluded_llm_metadata_keys\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[32m'file_name'\u001b[0m,\n",
       "        \u001b[32m'file_type'\u001b[0m,\n",
       "        \u001b[32m'file_size'\u001b[0m,\n",
       "        \u001b[32m'creation_date'\u001b[0m,\n",
       "        \u001b[32m'last_modified_date'\u001b[0m,\n",
       "        \u001b[32m'last_accessed_date'\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mrelationships\u001b[0m=\u001b[1m{\u001b[0m\n",
       "        \u001b[1m<\u001b[0m\u001b[1;95mNodeRelationship.SOURCE:\u001b[0m\u001b[39m \u001b[0m\u001b[32m'1'\u001b[0m\u001b[39m>: \u001b[0m\u001b[1;35mRelatedNodeInfo\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mnode_id\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'b8e65461-168c-4603-a276-a146a13b5fe9'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mnode_type\u001b[0m\u001b[39m=<ObjectType.DOCUMENT: \u001b[0m\u001b[32m'4'\u001b[0m\u001b[39m>,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mmetadata\u001b[0m\u001b[39m=\u001b[0m\u001b[1;39m{\u001b[0m\n",
       "\u001b[39m                \u001b[0m\u001b[32m'page_label'\u001b[0m\u001b[39m: \u001b[0m\u001b[32m'1'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                \u001b[0m\u001b[32m'file_name'\u001b[0m\u001b[39m: \u001b[0m\u001b[32m'aragpt2.pdf'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                \u001b[0m\u001b[32m'file_path'\u001b[0m\u001b[39m: \u001b[0m\u001b[32m'data/aragpt2.pdf'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                \u001b[0m\u001b[32m'file_type'\u001b[0m\u001b[39m: \u001b[0m\u001b[32m'application/pdf'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                \u001b[0m\u001b[32m'file_size'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;36m457776\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                \u001b[0m\u001b[32m'creation_date'\u001b[0m\u001b[39m: \u001b[0m\u001b[32m'2024-11-12'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                \u001b[0m\u001b[32m'last_modified_date'\u001b[0m\u001b[39m: \u001b[0m\u001b[32m'2024-10-22'\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[1;39m}\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mhash\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'be467e8635c423cf5e905a9469550ed6e5194fba229387b29d1ef0cf335d08de'\u001b[0m\n",
       "\u001b[39m        \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m        <NodeRelationship.NEXT: \u001b[0m\u001b[32m'3'\u001b[0m\u001b[39m>: \u001b[0m\u001b[1;35mRelatedNodeInfo\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mnode_id\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'6991976f-1ca4-4766-900b-1ecce132c2a0'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mnode_type\u001b[0m\u001b[39m=<ObjectType.TEXT: \u001b[0m\u001b[32m'1'\u001b[0m\u001b[1m>\u001b[0m,\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[33mhash\u001b[0m=\u001b[32m'2d3aa208bc0bae83732ad747eb239cc40eef454a4e693b6422ba4afc8288cdd5'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[33mtext\u001b[0m=\u001b[32m'Proceedings of the Sixth Arabic Natural Language Processing Workshop , pages 196–207\\nKyiv, Ukraine \u001b[0m\n",
       "\u001b[32m(\u001b[0m\u001b[32mVirtual\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, April 19, 2021.196ARAGPT2: Pre-T rained Transformer\\nfor Arabic Language Generation\\nWissam Antoun and \u001b[0m\n",
       "\u001b[32mFady Baly and Hazem Hajj\\nAmerican University of Beirut\\n\u001b[0m\u001b[32m{\u001b[0m\u001b[32mwfa07, fbg06, hh63 \u001b[0m\u001b[32m}\u001b[0m\u001b[32m@aub.edu.lb\\nAbstract\\nRecently, \u001b[0m\n",
       "\u001b[32mpre-trained transformer-based archi-\\ntectures have proven to be very efﬁcient atlanguage modeling and \u001b[0m\n",
       "\u001b[32munderstanding, giventhat they are trained on a large enough cor-pus. Applications in language generation \u001b[0m\n",
       "\u001b[32mfor\\nArabic are still lagging in comparison to other\\nNLP advances primarily due to the lack ofadvanced Arabic \u001b[0m\n",
       "\u001b[32mlanguage generation models.In this paper, we develop the ﬁrst advanced\\nArabic language generation model, \u001b[0m\n",
       "\u001b[32mAraGPT2,\\ntrained from scratch on a large Arabic corpusof internet text and news articles. Our largest\\nmodel, \u001b[0m\n",
       "\u001b[32mA\\nRAGPT2- MEGA , has 1.46 billion pa-\\nrameters, which makes it the largest Arabiclanguage model available. \u001b[0m\n",
       "\u001b[32mThe\\nMEGA model\\nwas evaluated and showed success on different\\ntasks including synthetic news generation, \u001b[0m\n",
       "\u001b[32mandzero-shot question answering. For text gener-\\nation, our best model achieves a perplexity of\\n29.8 on held-out \u001b[0m\n",
       "\u001b[32mWikipedia articles. A studyconducted with human evaluators showed thesigniﬁcant success of AraGPT2-mega in \u001b[0m\n",
       "\u001b[32mgen-erating news articles that are difﬁcult to dis-tinguish from articles written by humans. Wethus develop and \u001b[0m\n",
       "\u001b[32mrelease an automatic discrim-inator model with a 98% percent accuracy indetecting model-generated text. The \u001b[0m\n",
       "\u001b[32mmodelsare also publicly available\\n1, hoping to encour-\\nage new research directions and applicationsfor Arabic \u001b[0m\n",
       "\u001b[32mNLP.\\n1 Introduction\\nFew years ago, Natural language processing\\n\u001b[0m\u001b[32m(\u001b[0m\u001b[32mNLP\u001b[0m\u001b[32m)\u001b[0m\u001b[32m was revolutionized with the \u001b[0m\n",
       "\u001b[32mintroduction\\nof multi-head self-attention transformer architec-ture \u001b[0m\u001b[32m(\u001b[0m\u001b[32m Vaswani et al. ,2017 \u001b[0m\u001b[32m)\u001b[0m\u001b[32m.'\u001b[0m,\n",
       "    \u001b[33mmimetype\u001b[0m=\u001b[32m'text/plain'\u001b[0m,\n",
       "    \u001b[33mstart_char_idx\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "    \u001b[33mend_char_idx\u001b[0m=\u001b[1;36m1799\u001b[0m,\n",
       "    \u001b[33mtext_template\u001b[0m=\u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32mmetadata_str\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\n\u001b[0m\u001b[32m{\u001b[0m\u001b[32mcontent\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m,\n",
       "    \u001b[33mmetadata_template\u001b[0m=\u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32mkey\u001b[0m\u001b[32m}\u001b[0m\u001b[32m: \u001b[0m\u001b[32m{\u001b[0m\u001b[32mvalue\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m,\n",
       "    \u001b[33mmetadata_seperator\u001b[0m=\u001b[32m'\\n'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(len(nodes))\n",
    "print(nodes[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Vector and Summary Indexes (Indecies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "Settings.llm = OpenAI(model=GENERATION_MODEL_ID)\n",
    "Settings.embed_model = OpenAIEmbedding(model=EMBEDDING_MODEL_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SummaryIndex\n",
    "\n",
    "vector_index = VectorStoreIndex(nodes=nodes)\n",
    "summary_index = SummaryIndex(nodes=nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Query Engines\n",
    "\n",
    "Just tell the engine that there is a tool and here is a short description of how to use it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_query_engine = vector_index.as_query_engine()\n",
    "summary_query_engine = summary_index.as_query_engine(response_mode=\"tree_summarize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "\n",
    "\n",
    "vector_tool = QueryEngineTool(\n",
    "    query_engine=vector_query_engine,\n",
    "    metadata=ToolMetadata(\n",
    "        description=\"Useful for retrieving specific context from the aragpt2 paper.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "summary_tool = QueryEngineTool(\n",
    "    query_engine=summary_query_engine,\n",
    "    metadata=ToolMetadata(\n",
    "        description=\"Useful for summarization questions related to the aragpt2 paper.\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Router Query Engine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.selectors import LLMSingleSelector\n",
    "from llama_index.core.query_engine.router_query_engine import RouterQueryEngine\n",
    "\n",
    "agent = RouterQueryEngine(\n",
    "    selector=LLMSingleSelector.from_defaults(),\n",
    "    query_engine_tools=[vector_tool, summary_tool],\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 1: The question specifically asks for a summary of the AraGPT2 paper, making choice 2, which is useful for summarization questions, the most relevant..\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "query = \"Summarize the AraGPT2 paper for me please.\"\n",
    "response = agent.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The AraGPT2 paper presents the development of the first advanced Arabic language generation model, trained from \n",
       "scratch on a large corpus of Arabic text, including internet articles and news. The model, AraGPT2, comes in four \n",
       "variants: base, medium, large, and mega, with the largest variant containing <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.46</span> billion parameters, making it the\n",
       "largest Arabic language model available.\n",
       "\n",
       "The paper highlights the model's effectiveness in various tasks, such as synthetic news generation and zero-shot \n",
       "question answering, achieving a perplexity score of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">29.8</span> on held-out Wikipedia articles. Human evaluations \n",
       "demonstrated that AraGPT2-Mega can generate news articles that are often indistinguishable from those written by \n",
       "humans, successfully fooling approximately <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">60</span>% of evaluators.\n",
       "\n",
       "Additionally, the authors developed an automatic discriminator model that can detect machine-generated text with \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">98</span>% accuracy. The paper emphasizes the importance of making such models publicly available to foster research in \n",
       "Arabic NLP, while also addressing ethical concerns regarding potential misuse, such as generating fake news. The \n",
       "findings and methodologies outlined in the paper aim to encourage further exploration and applications in the field\n",
       "of Arabic natural language processing.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "The AraGPT2 paper presents the development of the first advanced Arabic language generation model, trained from \n",
       "scratch on a large corpus of Arabic text, including internet articles and news. The model, AraGPT2, comes in four \n",
       "variants: base, medium, large, and mega, with the largest variant containing \u001b[1;36m1.46\u001b[0m billion parameters, making it the\n",
       "largest Arabic language model available.\n",
       "\n",
       "The paper highlights the model's effectiveness in various tasks, such as synthetic news generation and zero-shot \n",
       "question answering, achieving a perplexity score of \u001b[1;36m29.8\u001b[0m on held-out Wikipedia articles. Human evaluations \n",
       "demonstrated that AraGPT2-Mega can generate news articles that are often indistinguishable from those written by \n",
       "humans, successfully fooling approximately \u001b[1;36m60\u001b[0m% of evaluators.\n",
       "\n",
       "Additionally, the authors developed an automatic discriminator model that can detect machine-generated text with \n",
       "\u001b[1;36m98\u001b[0m% accuracy. The paper emphasizes the importance of making such models publicly available to foster research in \n",
       "Arabic NLP, while also addressing ethical concerns regarding potential misuse, such as generating fake news. The \n",
       "findings and methodologies outlined in the paper aim to encourage further exploration and applications in the field\n",
       "of Arabic natural language processing.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 0: The question asks for specific context regarding the data used to train the AraGPT2 model, which aligns with retrieving specific information..\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "query = \"What data used to train the AraGPT2 model?\"\n",
    "response = agent.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The training dataset for the AraGPT2 model includes the following publicly available Arabic corpora:\n",
       "\n",
       "- The unshuffled OSCAR corpus\n",
       "- The Arabic Wikipedia dump from September <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2020</span>\n",
       "- The <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.</span>5B words Arabic Corpus\n",
       "- The OSIAN corpus\n",
       "- News articles provided by As-safir newspaper\n",
       "\n",
       "Additionally, the dataset underwent preprocessing, which involved filtering out short documents, removing repeated \n",
       "sentences, and replacing URLs, emails, and user mentions with special tokens, among other modifications.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "The training dataset for the AraGPT2 model includes the following publicly available Arabic corpora:\n",
       "\n",
       "- The unshuffled OSCAR corpus\n",
       "- The Arabic Wikipedia dump from September \u001b[1;36m2020\u001b[0m\n",
       "- The \u001b[1;36m1.\u001b[0m5B words Arabic Corpus\n",
       "- The OSIAN corpus\n",
       "- News articles provided by As-safir newspaper\n",
       "\n",
       "Additionally, the dataset underwent preprocessing, which involved filtering out short documents, removing repeated \n",
       "sentences, and replacing URLs, emails, and user mentions with special tokens, among other modifications.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(response.response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
