{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agentic RAG with LlamaIndex\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will experiment the agent worker and runner concept.\n",
    "\n",
    "- Define a reader to read the `pdf` sample file [AraGPT2](./data/aragpt2.pdf) paper.\n",
    "- Define a `splitter` to process the texts of the document.\n",
    "- Set the LLM embedding and generation model ids.\n",
    "- Create the engines from the Indexes and define a tool wrapper around them.\n",
    "- Define the agent worker and agent runner that utilize memory.\n",
    "- Debug the results by manually excuting the tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load env variables\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some constants\n",
    "GENERATION_MODEL_ID = \"gpt-4o-mini\"\n",
    "EMBEDDING_MODEL_ID = \"text-embedding-3-small\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "documents_reader = SimpleDirectoryReader(input_files=[\"./data/aragpt2.pdf\"])\n",
    "documents = documents_reader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id_</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'a119103a-0c4a-4a60-affb-6bce7c5e7bf4'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">embedding</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'page_label'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'1'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'file_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'aragpt2.pdf'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'file_path'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'data/aragpt2.pdf'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'file_type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'application/pdf'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'file_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">457776</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'creation_date'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2024-11-12'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'last_modified_date'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2024-10-22'</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">excluded_embed_metadata_keys</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'file_name'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'file_type'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'file_size'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'creation_date'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'last_modified_date'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'last_accessed_date'</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">excluded_llm_metadata_keys</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'file_name'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'file_type'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'file_size'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'creation_date'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'last_modified_date'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'last_accessed_date'</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">relationships</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">text</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Proceedings of the Sixth Arabic Natural Language Processing Workshop , pages 196–207\\nKyiv, Ukraine </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">(Virtual), April 19, 2021.196ARAGPT2: Pre-T rained Transformer\\nfor Arabic Language Generation\\nWissam Antoun and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Fady Baly and Hazem Hajj\\nAmerican University of Beirut\\n{wfa07, fbg06, hh63 }@aub.edu.lb\\nAbstract\\nRecently, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">pre-trained transformer-based archi-\\ntectures have proven to be very efﬁcient atlanguage modeling and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">understanding, giventhat they are trained on a large enough cor-pus. Applications in language generation </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">for\\nArabic are still lagging in comparison to other\\nNLP advances primarily due to the lack ofadvanced Arabic </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">language generation models.In this paper, we develop the ﬁrst advanced\\nArabic language generation model, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">AraGPT2,\\ntrained from scratch on a large Arabic corpusof internet text and news articles. Our largest\\nmodel, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">A\\nRAGPT2- MEGA , has 1.46 billion pa-\\nrameters, which makes it the largest Arabiclanguage model available. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">The\\nMEGA model\\nwas evaluated and showed success on different\\ntasks including synthetic news generation, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">andzero-shot question answering. For text gener-\\nation, our best model achieves a perplexity of\\n29.8 on held-out </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Wikipedia articles. A studyconducted with human evaluators showed thesigniﬁcant success of AraGPT2-mega in </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">gen-erating news articles that are difﬁcult to dis-tinguish from articles written by humans. Wethus develop and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">release an automatic discrim-inator model with a 98% percent accuracy indetecting model-generated text. The </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">modelsare also publicly available\\n1, hoping to encour-\\nage new research directions and applicationsfor Arabic </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">NLP.\\n1 Introduction\\nFew years ago, Natural language processing\\n(NLP) was revolutionized with the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">introduction\\nof multi-head self-attention transformer architec-ture ( Vaswani et al. ,2017 ). The </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">transformer\\nachieved superior performance compared to recur-\\nrent neural networks several NLP tasks </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">including\\nmachine translation, sentence classiﬁcation with\\n1Pretrained variants of A RAGPT2 (base, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">medium,\\nlarge, mega) and discriminator are publicly available </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">on\\ngithub.com/aub-mind/arabert/tree/master/aragpt2BERT ( Devlin et al. ,2019 ), and ELECTRA ( Clark\\net al. ,2020b</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">), and sentence completion with GPT-\\n2(Radford et al. ,2019 ), GROVER ( Zellers et al. ,\\n2019 ), and CTRL ( </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Keskar et al. ,2019 ). Recent\\nworks have shown that larger models pre-trained\\non larger datasets can further </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">improve performancei.e. RoBERTa ( Liu et al. ,2019 ), and XLM-R ( Con-\\nneau et al. ,2019 ).\\nOn the other hand, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">work on Arabic language\\nmodeling has mostly targeted natural language\\nunderstanding (NLU) by pre-training </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">transformer-\\nbased models using the Masked Language Model-\\ning (MLM) task i.e. A RABERT ( Antoun et al. ,\\n2020a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">). In contrast, Arabic text generation or\\ncausal language modeling hasn’t received much\\nattention. Few works such</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">as hULMonA ( ElJundi\\net al. ,2019 ) used next word prediction as a pre-\\ntraining task in for transfer learning in</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Arabic text\\nclassiﬁcation. ( Khooli ,2020 ) and ( Doiron ,2020 )\\nleveraged the existing GPT2 English model </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">andadapted it for Arabic using text from the Arabic\\nWikipedia dumps, which is sub-optimal for Arabic.\\nIn this </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">paper, the ﬁrst advanced language gener-\\nation models built from the grounds up on Arabic\\nlanguage have been </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">developed. The process of pre-\\ntraining A RAGPT2, a GPT -2 transformer model\\nfor the Arabic language is </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">described. The modelcomes in 4 size variants:\\nbase (135M2),medium\\n(370M), large (792M) and mega (1.46B3), </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">which\\nallows the exploration of A RAGPT2 in multiple ap-\\nplications with different data availability and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">com-\\nputational constraints. The perplexity measure is\\nused to automatically evaluate A RAGPT2. Fur-\\nthermore, a</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">human-based evaluation is provided,\\nwhich highlights the ability of A RAGPT2 to de-\\nceive human evaluators. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Finally, an A RAELEC-\\nTRA ( Antoun et al. ,2020b ) based detector is devel-\\n2Million Parameters\\n3Billion </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Parameters'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">mimetype</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'text/plain'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">start_char_idx</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">end_char_idx</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">text_template</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'{metadata_str}\\n\\n{content}'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">metadata_template</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'{key}: {value}'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">metadata_seperator</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'\\n'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid_\u001b[0m=\u001b[32m'a119103a-0c4a-4a60-affb-6bce7c5e7bf4'\u001b[0m,\n",
       "    \u001b[33membedding\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "        \u001b[32m'page_label'\u001b[0m: \u001b[32m'1'\u001b[0m,\n",
       "        \u001b[32m'file_name'\u001b[0m: \u001b[32m'aragpt2.pdf'\u001b[0m,\n",
       "        \u001b[32m'file_path'\u001b[0m: \u001b[32m'data/aragpt2.pdf'\u001b[0m,\n",
       "        \u001b[32m'file_type'\u001b[0m: \u001b[32m'application/pdf'\u001b[0m,\n",
       "        \u001b[32m'file_size'\u001b[0m: \u001b[1;36m457776\u001b[0m,\n",
       "        \u001b[32m'creation_date'\u001b[0m: \u001b[32m'2024-11-12'\u001b[0m,\n",
       "        \u001b[32m'last_modified_date'\u001b[0m: \u001b[32m'2024-10-22'\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[33mexcluded_embed_metadata_keys\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[32m'file_name'\u001b[0m,\n",
       "        \u001b[32m'file_type'\u001b[0m,\n",
       "        \u001b[32m'file_size'\u001b[0m,\n",
       "        \u001b[32m'creation_date'\u001b[0m,\n",
       "        \u001b[32m'last_modified_date'\u001b[0m,\n",
       "        \u001b[32m'last_accessed_date'\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mexcluded_llm_metadata_keys\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[32m'file_name'\u001b[0m,\n",
       "        \u001b[32m'file_type'\u001b[0m,\n",
       "        \u001b[32m'file_size'\u001b[0m,\n",
       "        \u001b[32m'creation_date'\u001b[0m,\n",
       "        \u001b[32m'last_modified_date'\u001b[0m,\n",
       "        \u001b[32m'last_accessed_date'\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mrelationships\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[33mtext\u001b[0m=\u001b[32m'Proceedings of the Sixth Arabic Natural Language Processing Workshop , pages 196–207\\nKyiv, Ukraine \u001b[0m\n",
       "\u001b[32m(\u001b[0m\u001b[32mVirtual\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, April 19, 2021.196ARAGPT2: Pre-T rained Transformer\\nfor Arabic Language Generation\\nWissam Antoun and \u001b[0m\n",
       "\u001b[32mFady Baly and Hazem Hajj\\nAmerican University of Beirut\\n\u001b[0m\u001b[32m{\u001b[0m\u001b[32mwfa07, fbg06, hh63 \u001b[0m\u001b[32m}\u001b[0m\u001b[32m@aub.edu.lb\\nAbstract\\nRecently, \u001b[0m\n",
       "\u001b[32mpre-trained transformer-based archi-\\ntectures have proven to be very efﬁcient atlanguage modeling and \u001b[0m\n",
       "\u001b[32munderstanding, giventhat they are trained on a large enough cor-pus. Applications in language generation \u001b[0m\n",
       "\u001b[32mfor\\nArabic are still lagging in comparison to other\\nNLP advances primarily due to the lack ofadvanced Arabic \u001b[0m\n",
       "\u001b[32mlanguage generation models.In this paper, we develop the ﬁrst advanced\\nArabic language generation model, \u001b[0m\n",
       "\u001b[32mAraGPT2,\\ntrained from scratch on a large Arabic corpusof internet text and news articles. Our largest\\nmodel, \u001b[0m\n",
       "\u001b[32mA\\nRAGPT2- MEGA , has 1.46 billion pa-\\nrameters, which makes it the largest Arabiclanguage model available. \u001b[0m\n",
       "\u001b[32mThe\\nMEGA model\\nwas evaluated and showed success on different\\ntasks including synthetic news generation, \u001b[0m\n",
       "\u001b[32mandzero-shot question answering. For text gener-\\nation, our best model achieves a perplexity of\\n29.8 on held-out \u001b[0m\n",
       "\u001b[32mWikipedia articles. A studyconducted with human evaluators showed thesigniﬁcant success of AraGPT2-mega in \u001b[0m\n",
       "\u001b[32mgen-erating news articles that are difﬁcult to dis-tinguish from articles written by humans. Wethus develop and \u001b[0m\n",
       "\u001b[32mrelease an automatic discrim-inator model with a 98% percent accuracy indetecting model-generated text. The \u001b[0m\n",
       "\u001b[32mmodelsare also publicly available\\n1, hoping to encour-\\nage new research directions and applicationsfor Arabic \u001b[0m\n",
       "\u001b[32mNLP.\\n1 Introduction\\nFew years ago, Natural language processing\\n\u001b[0m\u001b[32m(\u001b[0m\u001b[32mNLP\u001b[0m\u001b[32m)\u001b[0m\u001b[32m was revolutionized with the \u001b[0m\n",
       "\u001b[32mintroduction\\nof multi-head self-attention transformer architec-ture \u001b[0m\u001b[32m(\u001b[0m\u001b[32m Vaswani et al. ,2017 \u001b[0m\u001b[32m)\u001b[0m\u001b[32m. The \u001b[0m\n",
       "\u001b[32mtransformer\\nachieved superior performance compared to recur-\\nrent neural networks several NLP tasks \u001b[0m\n",
       "\u001b[32mincluding\\nmachine translation, sentence classiﬁcation with\\n1Pretrained variants of A RAGPT2 \u001b[0m\u001b[32m(\u001b[0m\u001b[32mbase, \u001b[0m\n",
       "\u001b[32mmedium,\\nlarge, mega\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and discriminator are publicly available \u001b[0m\n",
       "\u001b[32mon\\ngithub.com/aub-mind/arabert/tree/master/aragpt2BERT \u001b[0m\u001b[32m(\u001b[0m\u001b[32m Devlin et al. ,2019 \u001b[0m\u001b[32m)\u001b[0m\u001b[32m, and ELECTRA \u001b[0m\u001b[32m(\u001b[0m\u001b[32m Clark\\net al. ,2020b\u001b[0m\n",
       "\u001b[32m)\u001b[0m\u001b[32m, and sentence completion with GPT-\\n2\u001b[0m\u001b[32m(\u001b[0m\u001b[32mRadford et al. ,2019 \u001b[0m\u001b[32m)\u001b[0m\u001b[32m, GROVER \u001b[0m\u001b[32m(\u001b[0m\u001b[32m Zellers et al. ,\\n2019 \u001b[0m\u001b[32m)\u001b[0m\u001b[32m, and CTRL \u001b[0m\u001b[32m(\u001b[0m\u001b[32m \u001b[0m\n",
       "\u001b[32mKeskar et al. ,2019 \u001b[0m\u001b[32m)\u001b[0m\u001b[32m. Recent\\nworks have shown that larger models pre-trained\\non larger datasets can further \u001b[0m\n",
       "\u001b[32mimprove performancei.e. RoBERTa \u001b[0m\u001b[32m(\u001b[0m\u001b[32m Liu et al. ,2019 \u001b[0m\u001b[32m)\u001b[0m\u001b[32m, and XLM-R \u001b[0m\u001b[32m(\u001b[0m\u001b[32m Con-\\nneau et al. ,2019 \u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\nOn the other hand, \u001b[0m\n",
       "\u001b[32mwork on Arabic language\\nmodeling has mostly targeted natural language\\nunderstanding \u001b[0m\u001b[32m(\u001b[0m\u001b[32mNLU\u001b[0m\u001b[32m)\u001b[0m\u001b[32m by pre-training \u001b[0m\n",
       "\u001b[32mtransformer-\\nbased models using the Masked Language Model-\\ning \u001b[0m\u001b[32m(\u001b[0m\u001b[32mMLM\u001b[0m\u001b[32m)\u001b[0m\u001b[32m task i.e. A RABERT \u001b[0m\u001b[32m(\u001b[0m\u001b[32m Antoun et al. ,\\n2020a \u001b[0m\n",
       "\u001b[32m)\u001b[0m\u001b[32m. In contrast, Arabic text generation or\\ncausal language modeling hasn’t received much\\nattention. Few works such\u001b[0m\n",
       "\u001b[32mas hULMonA \u001b[0m\u001b[32m(\u001b[0m\u001b[32m ElJundi\\net al. ,2019 \u001b[0m\u001b[32m)\u001b[0m\u001b[32m used next word prediction as a pre-\\ntraining task in for transfer learning in\u001b[0m\n",
       "\u001b[32mArabic text\\nclassiﬁcation. \u001b[0m\u001b[32m(\u001b[0m\u001b[32m Khooli ,2020 \u001b[0m\u001b[32m)\u001b[0m\u001b[32m and \u001b[0m\u001b[32m(\u001b[0m\u001b[32m Doiron ,2020 \u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\nleveraged the existing GPT2 English model \u001b[0m\n",
       "\u001b[32mandadapted it for Arabic using text from the Arabic\\nWikipedia dumps, which is sub-optimal for Arabic.\\nIn this \u001b[0m\n",
       "\u001b[32mpaper, the ﬁrst advanced language gener-\\nation models built from the grounds up on Arabic\\nlanguage have been \u001b[0m\n",
       "\u001b[32mdeveloped. The process of pre-\\ntraining A RAGPT2, a GPT -2 transformer model\\nfor the Arabic language is \u001b[0m\n",
       "\u001b[32mdescribed. The modelcomes in 4 size variants:\\nbase \u001b[0m\u001b[32m(\u001b[0m\u001b[32m135M2\u001b[0m\u001b[32m)\u001b[0m\u001b[32m,medium\\n\u001b[0m\u001b[32m(\u001b[0m\u001b[32m370M\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, large \u001b[0m\u001b[32m(\u001b[0m\u001b[32m792M\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and mega \u001b[0m\u001b[32m(\u001b[0m\u001b[32m1.46B3\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, \u001b[0m\n",
       "\u001b[32mwhich\\nallows the exploration of A RAGPT2 in multiple ap-\\nplications with different data availability and \u001b[0m\n",
       "\u001b[32mcom-\\nputational constraints. The perplexity measure is\\nused to automatically evaluate A RAGPT2. Fur-\\nthermore, a\u001b[0m\n",
       "\u001b[32mhuman-based evaluation is provided,\\nwhich highlights the ability of A RAGPT2 to de-\\nceive human evaluators. \u001b[0m\n",
       "\u001b[32mFinally, an A RAELEC-\\nTRA \u001b[0m\u001b[32m(\u001b[0m\u001b[32m Antoun et al. ,2020b \u001b[0m\u001b[32m)\u001b[0m\u001b[32m based detector is devel-\\n2Million Parameters\\n3Billion \u001b[0m\n",
       "\u001b[32mParameters'\u001b[0m,\n",
       "    \u001b[33mmimetype\u001b[0m=\u001b[32m'text/plain'\u001b[0m,\n",
       "    \u001b[33mstart_char_idx\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mend_char_idx\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mtext_template\u001b[0m=\u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32mmetadata_str\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\n\u001b[0m\u001b[32m{\u001b[0m\u001b[32mcontent\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m,\n",
       "    \u001b[33mmetadata_template\u001b[0m=\u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32mkey\u001b[0m\u001b[32m}\u001b[0m\u001b[32m: \u001b[0m\u001b[32m{\u001b[0m\u001b[32mvalue\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m,\n",
       "    \u001b[33mmetadata_seperator\u001b[0m=\u001b[32m'\\n'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "sentence_splitter = SentenceSplitter(chunk_size=512, chunk_overlap=32)\n",
    "nodes = sentence_splitter.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">89</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m89\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TextNode</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id_</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'95a50672-6982-4e4a-abcd-ae36a1659daa'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">embedding</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'page_label'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'1'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'file_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'aragpt2.pdf'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'file_path'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'data/aragpt2.pdf'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'file_type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'application/pdf'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'file_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">457776</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'creation_date'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2024-11-12'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'last_modified_date'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2024-10-22'</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">excluded_embed_metadata_keys</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'file_name'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'file_type'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'file_size'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'creation_date'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'last_modified_date'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'last_accessed_date'</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">excluded_llm_metadata_keys</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'file_name'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'file_type'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'file_size'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'creation_date'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'last_modified_date'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'last_accessed_date'</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">relationships</span>=<span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">NodeRelationship.SOURCE:</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #008000; text-decoration-color: #008000\">'1'</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;: </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RelatedNodeInfo</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">node_id</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'a119103a-0c4a-4a60-affb-6bce7c5e7bf4'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">node_type</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;ObjectType.DOCUMENT: </span><span style=\"color: #008000; text-decoration-color: #008000\">'4'</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">metadata</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #008000; text-decoration-color: #008000\">'page_label'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'1'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #008000; text-decoration-color: #008000\">'file_name'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'aragpt2.pdf'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #008000; text-decoration-color: #008000\">'file_path'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'data/aragpt2.pdf'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #008000; text-decoration-color: #008000\">'file_type'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'application/pdf'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #008000; text-decoration-color: #008000\">'file_size'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">457776</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #008000; text-decoration-color: #008000\">'creation_date'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'2024-11-12'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #008000; text-decoration-color: #008000\">'last_modified_date'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'2024-10-22'</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">}</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">hash</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'be467e8635c423cf5e905a9469550ed6e5194fba229387b29d1ef0cf335d08de'</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">        &lt;NodeRelationship.PREVIOUS: </span><span style=\"color: #008000; text-decoration-color: #008000\">'2'</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;: </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RelatedNodeInfo</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">node_id</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'80e1413e-9f46-4cbb-8de5-9d4885461c9f'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">node_type</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;ObjectType.TEXT: </span><span style=\"color: #008000; text-decoration-color: #008000\">'1'</span><span style=\"font-weight: bold\">&gt;</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'page_label'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'1'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'file_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'aragpt2.pdf'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'file_path'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'data/aragpt2.pdf'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'file_type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'application/pdf'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'file_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">457776</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'creation_date'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2024-11-12'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'last_modified_date'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2024-10-22'</span>\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">hash</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'d29e9f18057bb077fc974a135476bbfa465cfbf92c45fa06545fe29f0a9eb880'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">text</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'The process of pre-\\ntraining A RAGPT2, a GPT -2 transformer model\\nfor the Arabic language is described.</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">The modelcomes in 4 size variants:\\nbase (135M2),medium\\n(370M), large (792M) and mega (1.46B3), which\\nallows the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">exploration of A RAGPT2 in multiple ap-\\nplications with different data availability and com-\\nputational </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">constraints. The perplexity measure is\\nused to automatically evaluate A RAGPT2. Fur-\\nthermore, a human-based </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">evaluation is provided,\\nwhich highlights the ability of A RAGPT2 to de-\\nceive human evaluators. Finally, an A </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">RAELEC-\\nTRA ( Antoun et al. ,2020b ) based detector is devel-\\n2Million Parameters\\n3Billion Parameters'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">mimetype</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'text/plain'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">start_char_idx</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3290</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">end_char_idx</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3930</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">text_template</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'{metadata_str}\\n\\n{content}'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">metadata_template</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'{key}: {value}'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">metadata_seperator</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'\\n'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mTextNode\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid_\u001b[0m=\u001b[32m'95a50672-6982-4e4a-abcd-ae36a1659daa'\u001b[0m,\n",
       "    \u001b[33membedding\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "        \u001b[32m'page_label'\u001b[0m: \u001b[32m'1'\u001b[0m,\n",
       "        \u001b[32m'file_name'\u001b[0m: \u001b[32m'aragpt2.pdf'\u001b[0m,\n",
       "        \u001b[32m'file_path'\u001b[0m: \u001b[32m'data/aragpt2.pdf'\u001b[0m,\n",
       "        \u001b[32m'file_type'\u001b[0m: \u001b[32m'application/pdf'\u001b[0m,\n",
       "        \u001b[32m'file_size'\u001b[0m: \u001b[1;36m457776\u001b[0m,\n",
       "        \u001b[32m'creation_date'\u001b[0m: \u001b[32m'2024-11-12'\u001b[0m,\n",
       "        \u001b[32m'last_modified_date'\u001b[0m: \u001b[32m'2024-10-22'\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[33mexcluded_embed_metadata_keys\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[32m'file_name'\u001b[0m,\n",
       "        \u001b[32m'file_type'\u001b[0m,\n",
       "        \u001b[32m'file_size'\u001b[0m,\n",
       "        \u001b[32m'creation_date'\u001b[0m,\n",
       "        \u001b[32m'last_modified_date'\u001b[0m,\n",
       "        \u001b[32m'last_accessed_date'\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mexcluded_llm_metadata_keys\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[32m'file_name'\u001b[0m,\n",
       "        \u001b[32m'file_type'\u001b[0m,\n",
       "        \u001b[32m'file_size'\u001b[0m,\n",
       "        \u001b[32m'creation_date'\u001b[0m,\n",
       "        \u001b[32m'last_modified_date'\u001b[0m,\n",
       "        \u001b[32m'last_accessed_date'\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mrelationships\u001b[0m=\u001b[1m{\u001b[0m\n",
       "        \u001b[1m<\u001b[0m\u001b[1;95mNodeRelationship.SOURCE:\u001b[0m\u001b[39m \u001b[0m\u001b[32m'1'\u001b[0m\u001b[39m>: \u001b[0m\u001b[1;35mRelatedNodeInfo\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mnode_id\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'a119103a-0c4a-4a60-affb-6bce7c5e7bf4'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mnode_type\u001b[0m\u001b[39m=<ObjectType.DOCUMENT: \u001b[0m\u001b[32m'4'\u001b[0m\u001b[39m>,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mmetadata\u001b[0m\u001b[39m=\u001b[0m\u001b[1;39m{\u001b[0m\n",
       "\u001b[39m                \u001b[0m\u001b[32m'page_label'\u001b[0m\u001b[39m: \u001b[0m\u001b[32m'1'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                \u001b[0m\u001b[32m'file_name'\u001b[0m\u001b[39m: \u001b[0m\u001b[32m'aragpt2.pdf'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                \u001b[0m\u001b[32m'file_path'\u001b[0m\u001b[39m: \u001b[0m\u001b[32m'data/aragpt2.pdf'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                \u001b[0m\u001b[32m'file_type'\u001b[0m\u001b[39m: \u001b[0m\u001b[32m'application/pdf'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                \u001b[0m\u001b[32m'file_size'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;36m457776\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                \u001b[0m\u001b[32m'creation_date'\u001b[0m\u001b[39m: \u001b[0m\u001b[32m'2024-11-12'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m                \u001b[0m\u001b[32m'last_modified_date'\u001b[0m\u001b[39m: \u001b[0m\u001b[32m'2024-10-22'\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[1;39m}\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mhash\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'be467e8635c423cf5e905a9469550ed6e5194fba229387b29d1ef0cf335d08de'\u001b[0m\n",
       "\u001b[39m        \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m        <NodeRelationship.PREVIOUS: \u001b[0m\u001b[32m'2'\u001b[0m\u001b[39m>: \u001b[0m\u001b[1;35mRelatedNodeInfo\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mnode_id\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'80e1413e-9f46-4cbb-8de5-9d4885461c9f'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mnode_type\u001b[0m\u001b[39m=<ObjectType.TEXT: \u001b[0m\u001b[32m'1'\u001b[0m\u001b[1m>\u001b[0m,\n",
       "            \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "                \u001b[32m'page_label'\u001b[0m: \u001b[32m'1'\u001b[0m,\n",
       "                \u001b[32m'file_name'\u001b[0m: \u001b[32m'aragpt2.pdf'\u001b[0m,\n",
       "                \u001b[32m'file_path'\u001b[0m: \u001b[32m'data/aragpt2.pdf'\u001b[0m,\n",
       "                \u001b[32m'file_type'\u001b[0m: \u001b[32m'application/pdf'\u001b[0m,\n",
       "                \u001b[32m'file_size'\u001b[0m: \u001b[1;36m457776\u001b[0m,\n",
       "                \u001b[32m'creation_date'\u001b[0m: \u001b[32m'2024-11-12'\u001b[0m,\n",
       "                \u001b[32m'last_modified_date'\u001b[0m: \u001b[32m'2024-10-22'\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[33mhash\u001b[0m=\u001b[32m'd29e9f18057bb077fc974a135476bbfa465cfbf92c45fa06545fe29f0a9eb880'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[33mtext\u001b[0m=\u001b[32m'The process of pre-\\ntraining A RAGPT2, a GPT -2 transformer model\\nfor the Arabic language is described.\u001b[0m\n",
       "\u001b[32mThe modelcomes in 4 size variants:\\nbase \u001b[0m\u001b[32m(\u001b[0m\u001b[32m135M2\u001b[0m\u001b[32m)\u001b[0m\u001b[32m,medium\\n\u001b[0m\u001b[32m(\u001b[0m\u001b[32m370M\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, large \u001b[0m\u001b[32m(\u001b[0m\u001b[32m792M\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and mega \u001b[0m\u001b[32m(\u001b[0m\u001b[32m1.46B3\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, which\\nallows the \u001b[0m\n",
       "\u001b[32mexploration of A RAGPT2 in multiple ap-\\nplications with different data availability and com-\\nputational \u001b[0m\n",
       "\u001b[32mconstraints. The perplexity measure is\\nused to automatically evaluate A RAGPT2. Fur-\\nthermore, a human-based \u001b[0m\n",
       "\u001b[32mevaluation is provided,\\nwhich highlights the ability of A RAGPT2 to de-\\nceive human evaluators. Finally, an A \u001b[0m\n",
       "\u001b[32mRAELEC-\\nTRA \u001b[0m\u001b[32m(\u001b[0m\u001b[32m Antoun et al. ,2020b \u001b[0m\u001b[32m)\u001b[0m\u001b[32m based detector is devel-\\n2Million Parameters\\n3Billion Parameters'\u001b[0m,\n",
       "    \u001b[33mmimetype\u001b[0m=\u001b[32m'text/plain'\u001b[0m,\n",
       "    \u001b[33mstart_char_idx\u001b[0m=\u001b[1;36m3290\u001b[0m,\n",
       "    \u001b[33mend_char_idx\u001b[0m=\u001b[1;36m3930\u001b[0m,\n",
       "    \u001b[33mtext_template\u001b[0m=\u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32mmetadata_str\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\n\u001b[0m\u001b[32m{\u001b[0m\u001b[32mcontent\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m,\n",
       "    \u001b[33mmetadata_template\u001b[0m=\u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32mkey\u001b[0m\u001b[32m}\u001b[0m\u001b[32m: \u001b[0m\u001b[32m{\u001b[0m\u001b[32mvalue\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m,\n",
       "    \u001b[33mmetadata_seperator\u001b[0m=\u001b[32m'\\n'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(len(nodes))\n",
    "print(nodes[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Backend Settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "Settings.llm = OpenAI(model=GENERATION_MODEL_ID)\n",
    "Settings.embed_model = OpenAIEmbedding(model=EMBEDDING_MODEL_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Vector and Summary Indecies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SummaryIndex\n",
    "\n",
    "vector_index = VectorStoreIndex(nodes=nodes)\n",
    "summary_index = SummaryIndex(nodes=nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Indecies to Tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_engine = vector_index.as_query_engine()\n",
    "vector_tool = QueryEngineTool(\n",
    "    query_engine=vector_engine,\n",
    "    metadata=ToolMetadata(\n",
    "        name=\"vector_tool\",\n",
    "        description=\"Useful for retrieving specific context from the aragpt2 paper.\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_engine = summary_index.as_query_engine(response_mode=\"tree_summarize\")\n",
    "summary_tool = QueryEngineTool(\n",
    "    query_engine=summary_engine,\n",
    "    metadata=ToolMetadata(\n",
    "        name=\"summary_tool\",\n",
    "        description=\"Useful for summarization questions related to the aragpt2 paper.\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Agent Worker and Runner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import FunctionCallingAgentWorker, AgentRunner\n",
    "\n",
    "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "    tools=[vector_tool, summary_tool], verbose=True\n",
    ")\n",
    "agent_runner = AgentRunner(agent_worker=agent_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: What datasets were used to train the AraGPT2 model?\n",
      "=== Calling Function ===\n",
      "Calling function: vector_tool with args: {\"input\": \"datasets used to train the AraGPT2 model\"}\n",
      "=== Function Output ===\n",
      "The training dataset for the AraGPT2 model includes the following publicly available Arabic corpora:\n",
      "\n",
      "- The unshuffled OSCAR corpus\n",
      "- The Arabic Wikipedia dump from September 2020\n",
      "- The 1.5B words Arabic Corpus\n",
      "- The OSIAN corpus\n",
      "- News articles provided by As-safir newspaper\n",
      "\n",
      "Additionally, the dataset underwent preprocessing, which involved filtering out short documents, removing repeated sentences, and replacing URLs, emails, and user mentions with special tokens, among other modifications.\n",
      "=== LLM Response ===\n",
      "The AraGPT2 model was trained on several publicly available Arabic corpora, including:\n",
      "\n",
      "- The unshuffled OSCAR corpus\n",
      "- The Arabic Wikipedia dump from September 2020\n",
      "- The 1.5B words Arabic Corpus\n",
      "- The OSIAN corpus\n",
      "- News articles from the As-safir newspaper\n",
      "\n",
      "The dataset also underwent preprocessing, which included filtering out short documents, removing repeated sentences, and replacing URLs, emails, and user mentions with special tokens, among other modifications.\n"
     ]
    }
   ],
   "source": [
    "query = \"What datasets were used to train the AraGPT2 model?\"\n",
    "response = agent_runner.chat(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: What was the combined size in GBs of those data?\n",
      "=== Calling Function ===\n",
      "Calling function: vector_tool with args: {\"input\": \"combined size in GBs of datasets used to train AraGPT2 model\"}\n",
      "=== Function Output ===\n",
      "The combined size in GBs of the datasets used to train the AraGPT2 model is not specified in the provided information.\n",
      "=== LLM Response ===\n",
      "The combined size in GBs of the datasets used to train the AraGPT2 model is not specified in the available information.\n"
     ]
    }
   ],
   "source": [
    "query = \"What was the combined size in GBs of those data?\"\n",
    "response = agent_runner.chat(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">page_label: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>\n",
       "file_name: aragpt2.pdf\n",
       "file_path: data/aragpt2.pdf\n",
       "file_type: application/pdf\n",
       "file_size: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">457776</span>\n",
       "creation_date: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>\n",
       "last_modified_date: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span>\n",
       "\n",
       "199Model Size Architecture Context Size Emb. Size Heads Layers Optimizer\n",
       "Base 135M GPT2 <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1024</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> LAMB\n",
       "Medium 370M GPT2 <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1024</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1024</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24</span> LAMB\n",
       "Large 792M GROVER <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1024</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1280</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">36</span> Adafactor\n",
       "Mega <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.</span>46B GROVER <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1024</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1536</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48</span> Adafactor\n",
       "Table <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>: A RAGPT2 model variants with sizes, architecture and optimizer\n",
       "Model Batch Size Learning Rate Steps Time <span style=\"font-weight: bold\">(</span>days<span style=\"font-weight: bold\">)</span> PPL\n",
       "Base <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1792</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.27e-3</span> 120K <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.5</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">55.8</span>\n",
       "Medium* <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">80</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3e-4</span> 1M <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">45.7</span>\n",
       "Large <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">256</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-4</span> 220K <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">36.6</span>\n",
       "Mega <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">256</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-4</span> 780K <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">29.8</span>\n",
       "Table <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>: A RAGPT2 training details and validation perplexity. * Medium was trained on a TPUv3-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> with a small\n",
       "batch size, since the model was not converging with a large batch size\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> Experiments and Evaluation\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.1</span> Pre-training Setup\n",
       "All models were trained on a TPUv3-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span> slice9\n",
       "with different batch sizes and the total number\n",
       "of steps as shown in Table <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.</span>Base and mega\n",
       "were trained for approximately <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> epochs, while\n",
       "medium and large were trained for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> and <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>\n",
       "epochs respectively, due to TPU access limitations.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.2</span> Numerical Evaluation\n",
       "For the validation dataset, the Arabic Wikipedia\n",
       "articles that were published after August <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2020</span>\n",
       "were used, since older articles were included in\n",
       "the September Wikipedia dump. The perplexity\n",
       "score was selected as a numerical evaluation met-\n",
       "ric since it measures the degree of ’uncertainty’ a\n",
       "model has assigning probabilities to the test text.\n",
       "Table 2shows that, unsurprisingly, validation per-\n",
       "plexity keeps improving with larger model sizes.\n",
       "In fact, the model is still under-ﬁtting the validation\n",
       "set from Wikipedia. The generation capabilities of\n",
       "the different variants of A RAGPT2 is illustrated\n",
       "through the selected examples in Appendix A.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "page_label: \u001b[1;36m4\u001b[0m\n",
       "file_name: aragpt2.pdf\n",
       "file_path: data/aragpt2.pdf\n",
       "file_type: application/pdf\n",
       "file_size: \u001b[1;36m457776\u001b[0m\n",
       "creation_date: \u001b[1;36m2024\u001b[0m-\u001b[1;36m11\u001b[0m-\u001b[1;36m12\u001b[0m\n",
       "last_modified_date: \u001b[1;36m2024\u001b[0m-\u001b[1;36m10\u001b[0m-\u001b[1;36m22\u001b[0m\n",
       "\n",
       "199Model Size Architecture Context Size Emb. Size Heads Layers Optimizer\n",
       "Base 135M GPT2 \u001b[1;36m1024\u001b[0m \u001b[1;36m768\u001b[0m \u001b[1;36m12\u001b[0m \u001b[1;36m12\u001b[0m LAMB\n",
       "Medium 370M GPT2 \u001b[1;36m1024\u001b[0m \u001b[1;36m1024\u001b[0m \u001b[1;36m16\u001b[0m \u001b[1;36m24\u001b[0m LAMB\n",
       "Large 792M GROVER \u001b[1;36m1024\u001b[0m \u001b[1;36m1280\u001b[0m \u001b[1;36m20\u001b[0m \u001b[1;36m36\u001b[0m Adafactor\n",
       "Mega \u001b[1;36m1.\u001b[0m46B GROVER \u001b[1;36m1024\u001b[0m \u001b[1;36m1536\u001b[0m \u001b[1;36m24\u001b[0m \u001b[1;36m48\u001b[0m Adafactor\n",
       "Table \u001b[1;36m1\u001b[0m: A RAGPT2 model variants with sizes, architecture and optimizer\n",
       "Model Batch Size Learning Rate Steps Time \u001b[1m(\u001b[0mdays\u001b[1m)\u001b[0m PPL\n",
       "Base \u001b[1;36m1792\u001b[0m \u001b[1;36m1.27e-3\u001b[0m 120K \u001b[1;36m1.5\u001b[0m \u001b[1;36m55.8\u001b[0m\n",
       "Medium* \u001b[1;36m80\u001b[0m \u001b[1;36m3e-4\u001b[0m 1M \u001b[1;36m23\u001b[0m \u001b[1;36m45.7\u001b[0m\n",
       "Large \u001b[1;36m256\u001b[0m \u001b[1;36m1e-4\u001b[0m 220K \u001b[1;36m3\u001b[0m \u001b[1;36m36.6\u001b[0m\n",
       "Mega \u001b[1;36m256\u001b[0m \u001b[1;36m1e-4\u001b[0m 780K \u001b[1;36m9\u001b[0m \u001b[1;36m29.8\u001b[0m\n",
       "Table \u001b[1;36m2\u001b[0m: A RAGPT2 training details and validation perplexity. * Medium was trained on a TPUv3-\u001b[1;36m8\u001b[0m with a small\n",
       "batch size, since the model was not converging with a large batch size\n",
       "\u001b[1;36m4\u001b[0m Experiments and Evaluation\n",
       "\u001b[1;36m4.1\u001b[0m Pre-training Setup\n",
       "All models were trained on a TPUv3-\u001b[1;36m128\u001b[0m slice9\n",
       "with different batch sizes and the total number\n",
       "of steps as shown in Table \u001b[1;36m2.\u001b[0mBase and mega\n",
       "were trained for approximately \u001b[1;36m20\u001b[0m epochs, while\n",
       "medium and large were trained for \u001b[1;36m10\u001b[0m and \u001b[1;36m6\u001b[0m\n",
       "epochs respectively, due to TPU access limitations.\n",
       "\u001b[1;36m4.2\u001b[0m Numerical Evaluation\n",
       "For the validation dataset, the Arabic Wikipedia\n",
       "articles that were published after August \u001b[1;36m2020\u001b[0m\n",
       "were used, since older articles were included in\n",
       "the September Wikipedia dump. The perplexity\n",
       "score was selected as a numerical evaluation met-\n",
       "ric since it measures the degree of ’uncertainty’ a\n",
       "model has assigning probabilities to the test text.\n",
       "Table 2shows that, unsurprisingly, validation per-\n",
       "plexity keeps improving with larger model sizes.\n",
       "In fact, the model is still under-ﬁtting the validation\n",
       "set from Wikipedia. The generation capabilities of\n",
       "the different variants of A RAGPT2 is illustrated\n",
       "through the selected examples in Appendix A.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(response.source_nodes[0].get_content(metadata_mode=\"all\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Debugging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "    tools=[vector_tool, summary_tool], verbose=True\n",
    ")\n",
    "agent_runner = AgentRunner(agent_worker=agent_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What datasets were used to train the AraGPT2 models and what evaluation methods were used?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = agent_runner.create_task(input=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Task</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">task_id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'d916bd52-8965-493e-8280-2e412525ed9a'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">input</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'What datasets were used to train the AraGPT2 models and what evaluation methods were used?'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">memory</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatMemoryBuffer</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">chat_store</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SimpleChatStore</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">store</span>=<span style=\"font-weight: bold\">{})</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">chat_store_key</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chat_history'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">token_limit</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3000</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">tokenizer_fn</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">functools</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.partial</span><span style=\"font-weight: bold\">(&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">bound</span><span style=\"color: #000000; text-decoration-color: #000000\"> method Encoding.encode of &lt;Encoding </span><span style=\"color: #008000; text-decoration-color: #008000\">'cl100k_base'</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;&gt;, </span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">allowed_special</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'all'</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #808000; text-decoration-color: #808000\">callback_manager</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;llama_index.core.callbacks.base.CallbackManager object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7fb8a4b794d0</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #808000; text-decoration-color: #808000\">extra_state</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #008000; text-decoration-color: #008000\">'sources'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[]</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #008000; text-decoration-color: #008000\">'n_function_calls'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #008000; text-decoration-color: #008000\">'new_memory'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatMemoryBuffer</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">chat_store</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SimpleChatStore</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">store</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{})</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">chat_store_key</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'chat_history'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">token_limit</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3000</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">tokenizer_fn</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">functools</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.partial</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #000000; text-decoration-color: #000000\">&lt;bound method Encoding.encode of &lt;Encoding </span><span style=\"color: #008000; text-decoration-color: #008000\">'cl100k_base'</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span><span style=\"font-weight: bold\">&gt;</span>, \n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">allowed_special</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'all'</span><span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mTask\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mtask_id\u001b[0m=\u001b[32m'd916bd52-8965-493e-8280-2e412525ed9a'\u001b[0m,\n",
       "    \u001b[33minput\u001b[0m=\u001b[32m'What datasets were used to train the AraGPT2 models and what evaluation methods were used?'\u001b[0m,\n",
       "    \u001b[33mmemory\u001b[0m=\u001b[1;35mChatMemoryBuffer\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mchat_store\u001b[0m=\u001b[1;35mSimpleChatStore\u001b[0m\u001b[1m(\u001b[0m\u001b[33mstore\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[33mchat_store_key\u001b[0m=\u001b[32m'chat_history'\u001b[0m,\n",
       "        \u001b[33mtoken_limit\u001b[0m=\u001b[1;36m3000\u001b[0m,\n",
       "        \u001b[33mtokenizer_fn\u001b[0m=\u001b[1;35mfunctools\u001b[0m\u001b[1;35m.partial\u001b[0m\u001b[1m(\u001b[0m\u001b[1m<\u001b[0m\u001b[1;95mbound\u001b[0m\u001b[39m method Encoding.encode of <Encoding \u001b[0m\u001b[32m'cl100k_base'\u001b[0m\u001b[39m>>, \u001b[0m\n",
       "\u001b[33mallowed_special\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'all'\u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39m    \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m    \u001b[0m\u001b[33mcallback_manager\u001b[0m\u001b[39m=<llama_index.core.callbacks.base.CallbackManager object at \u001b[0m\u001b[1;36m0x7fb8a4b794d0\u001b[0m\u001b[39m>,\u001b[0m\n",
       "\u001b[39m    \u001b[0m\u001b[33mextra_state\u001b[0m\u001b[39m=\u001b[0m\u001b[1;39m{\u001b[0m\n",
       "\u001b[39m        \u001b[0m\u001b[32m'sources'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;39m[\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m        \u001b[0m\u001b[32m'n_function_calls'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m        \u001b[0m\u001b[32m'new_memory'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;35mChatMemoryBuffer\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mchat_store\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mSimpleChatStore\u001b[0m\u001b[1;39m(\u001b[0m\u001b[33mstore\u001b[0m\u001b[39m=\u001b[0m\u001b[1;39m{\u001b[0m\u001b[1;39m}\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mchat_store_key\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'chat_history'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mtoken_limit\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m3000\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[33mtokenizer_fn\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mfunctools\u001b[0m\u001b[1;35m.partial\u001b[0m\u001b[1;39m(\u001b[0m\u001b[39m<bound method Encoding.encode of <Encoding \u001b[0m\u001b[32m'cl100k_base'\u001b[0m\u001b[39m>\u001b[0m\u001b[1m>\u001b[0m, \n",
       "\u001b[33mallowed_special\u001b[0m=\u001b[32m'all'\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: What datasets were used to train the AraGPT2 models and what evaluation methods were used?\n",
      "=== Calling Function ===\n",
      "Calling function: vector_tool with args: {\"input\": \"datasets used to train AraGPT2 models\"}\n",
      "=== Function Output ===\n",
      "The training dataset for the AraGPT2 models includes the following publicly available Arabic corpora:\n",
      "\n",
      "- The unshuffled OSCAR corpus\n",
      "- The Arabic Wikipedia dump from September 2020\n",
      "- The 1.5B words Arabic Corpus\n",
      "- The OSIAN corpus\n",
      "- News articles provided by As-safir newspaper\n",
      "\n",
      "Additionally, the dataset was preprocessed by filtering out short documents, removing repeated sentences, and replacing URLs, emails, and user mentions with special tokens, among other modifications.\n",
      "=== Calling Function ===\n",
      "Calling function: vector_tool with args: {\"input\": \"evaluation methods used for AraGPT2 models\"}\n",
      "=== Function Output ===\n",
      "The evaluation methods used for AraGPT2 models include an automatic evaluation based on the perplexity measure, as well as a human-based evaluation that assesses the model's ability to deceive human evaluators.\n"
     ]
    }
   ],
   "source": [
    "step_output = agent_runner.run_step(task_id=task.task_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "completed_steps = agent_runner.get_completed_steps(task_id=task.task_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m1\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(len(completed_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "upcoming_steps = agent_runner.get_upcoming_steps(task_id=task.task_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TaskStep</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">task_id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'d916bd52-8965-493e-8280-2e412525ed9a'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">step_id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'c2e06854-221b-46d9-8d3e-33a254b1443f'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">input</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">step_state</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">next_steps</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">prev_steps</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">is_ready</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1;35mTaskStep\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mtask_id\u001b[0m=\u001b[32m'd916bd52-8965-493e-8280-2e412525ed9a'\u001b[0m,\n",
       "        \u001b[33mstep_id\u001b[0m=\u001b[32m'c2e06854-221b-46d9-8d3e-33a254b1443f'\u001b[0m,\n",
       "        \u001b[33minput\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33mstep_state\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mnext_steps\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mprev_steps\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mis_ready\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(upcoming_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LLM Response ===\n",
      "The AraGPT2 models were trained using several publicly available Arabic corpora, including:\n",
      "\n",
      "- The unshuffled OSCAR corpus\n",
      "- The Arabic Wikipedia dump from September 2020\n",
      "- The 1.5B words Arabic Corpus\n",
      "- The OSIAN corpus\n",
      "- News articles provided by As-safir newspaper\n",
      "\n",
      "The dataset was preprocessed by filtering out short documents, removing repeated sentences, and replacing URLs, emails, and user mentions with special tokens, among other modifications.\n",
      "\n",
      "For evaluation, the AraGPT2 models employed two methods:\n",
      "\n",
      "1. An automatic evaluation based on the perplexity measure.\n",
      "2. A human-based evaluation that assesses the model's ability to deceive human evaluators.\n"
     ]
    }
   ],
   "source": [
    "step_output = agent_runner.run_step(task_id=task.task_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TaskStepOutput</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">output</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AgentChatResponse</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"The AraGPT2 models were trained using several publicly available Arabic corpora, including:\\n\\n- </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">The unshuffled OSCAR corpus\\n- The Arabic Wikipedia dump from September 2020\\n- The 1.5B words Arabic Corpus\\n- The</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">OSIAN corpus\\n- News articles provided by As-safir newspaper\\n\\nThe dataset was preprocessed by filtering out short</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">documents, removing repeated sentences, and replacing URLs, emails, and user mentions with special tokens, among </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">other modifications.\\n\\nFor evaluation, the AraGPT2 models employed two methods:\\n\\n1. An automatic evaluation </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">based on the perplexity measure.\\n2. A human-based evaluation that assesses the model's ability to deceive human </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">evaluators.\"</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">sources</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">source_nodes</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">is_dummy_stream</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">task_step</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TaskStep</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">task_id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'d916bd52-8965-493e-8280-2e412525ed9a'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">step_id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'c2e06854-221b-46d9-8d3e-33a254b1443f'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">input</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">step_state</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">next_steps</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">prev_steps</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">is_ready</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">next_steps</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_last</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mTaskStepOutput\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33moutput\u001b[0m=\u001b[1;35mAgentChatResponse\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mresponse\u001b[0m=\u001b[32m\"The\u001b[0m\u001b[32m AraGPT2 models were trained using several publicly available Arabic corpora, including:\\n\\n- \u001b[0m\n",
       "\u001b[32mThe unshuffled OSCAR corpus\\n- The Arabic Wikipedia dump from September 2020\\n- The 1.5B words Arabic Corpus\\n- The\u001b[0m\n",
       "\u001b[32mOSIAN corpus\\n- News articles provided by As-safir newspaper\\n\\nThe dataset was preprocessed by filtering out short\u001b[0m\n",
       "\u001b[32mdocuments, removing repeated sentences, and replacing URLs, emails, and user mentions with special tokens, among \u001b[0m\n",
       "\u001b[32mother modifications.\\n\\nFor evaluation, the AraGPT2 models employed two methods:\\n\\n1. An automatic evaluation \u001b[0m\n",
       "\u001b[32mbased on the perplexity measure.\\n2. A human-based evaluation that assesses the model's ability to deceive human \u001b[0m\n",
       "\u001b[32mevaluators.\"\u001b[0m,\n",
       "        \u001b[33msources\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[33msource_nodes\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[33mis_dummy_stream\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[33mtask_step\u001b[0m=\u001b[1;35mTaskStep\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mtask_id\u001b[0m=\u001b[32m'd916bd52-8965-493e-8280-2e412525ed9a'\u001b[0m,\n",
       "        \u001b[33mstep_id\u001b[0m=\u001b[32m'c2e06854-221b-46d9-8d3e-33a254b1443f'\u001b[0m,\n",
       "        \u001b[33minput\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33mstep_state\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mnext_steps\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mprev_steps\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mis_ready\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[33mnext_steps\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33mis_last\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(step_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_runner.get_upcoming_steps(task_id=task.task_id) # no upcomming steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The AraGPT2 models were trained using several publicly available Arabic corpora, including:\n",
       "\n",
       "- The unshuffled OSCAR corpus\n",
       "- The Arabic Wikipedia dump from September <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2020</span>\n",
       "- The <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.</span>5B words Arabic Corpus\n",
       "- The OSIAN corpus\n",
       "- News articles provided by As-safir newspaper\n",
       "\n",
       "The dataset was preprocessed by filtering out short documents, removing repeated sentences, and replacing URLs, \n",
       "emails, and user mentions with special tokens, among other modifications.\n",
       "\n",
       "For evaluation, the AraGPT2 models employed two methods:\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. An automatic evaluation based on the perplexity measure.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. A human-based evaluation that assesses the model's ability to deceive human evaluators.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "The AraGPT2 models were trained using several publicly available Arabic corpora, including:\n",
       "\n",
       "- The unshuffled OSCAR corpus\n",
       "- The Arabic Wikipedia dump from September \u001b[1;36m2020\u001b[0m\n",
       "- The \u001b[1;36m1.\u001b[0m5B words Arabic Corpus\n",
       "- The OSIAN corpus\n",
       "- News articles provided by As-safir newspaper\n",
       "\n",
       "The dataset was preprocessed by filtering out short documents, removing repeated sentences, and replacing URLs, \n",
       "emails, and user mentions with special tokens, among other modifications.\n",
       "\n",
       "For evaluation, the AraGPT2 models employed two methods:\n",
       "\n",
       "\u001b[1;36m1\u001b[0m. An automatic evaluation based on the perplexity measure.\n",
       "\u001b[1;36m2\u001b[0m. A human-based evaluation that assesses the model's ability to deceive human evaluators.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = agent_runner.finalize_response(task_id=task.task_id)\n",
    "print(response.response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
